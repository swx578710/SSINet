{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4947dd72-8315-4eb2-b379-df0acb186242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy import io\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "import sys;\n",
    "from esinet.evaluate import eval_mse\n",
    "# sys.path.insert(0, '../')\n",
    "from esinet import Simulation, Net, util, evaluate\n",
    "from forward import create_forward_model, get_info\n",
    "from matplotlib import pyplot as plt\n",
    "from esinet.util import calculate_source\n",
    "import pickle\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0cbf8373-e0bc-4b95-bfd8-ef028b36f53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_prep_data(data):\n",
    "\n",
    "    data = np.swapaxes(data, 1,2)\n",
    "\n",
    "    # 获取数据维度\n",
    "    num_samples, num_timepoints, num_channels = data.shape\n",
    "    \n",
    "    # 将数据类型转换为 np.float32\n",
    "    data = data.astype(np.float32)\n",
    "    \n",
    "    # 对每个样本（脑电信号的一个时间点）进行处理\n",
    "    for i in range(num_samples):\n",
    "        for j in range(num_timepoints):\n",
    "            # 获取当前样本的数据\n",
    "            sample_data = data[i, j, :]\n",
    "            \n",
    "            # 假设你想要进行去除平均值和标准化的预处理\n",
    "            # 去除平均值\n",
    "            sample_data_mean = np.mean(sample_data)\n",
    "            sample_data_std = np.std(sample_data)\n",
    "            sample_data -= sample_data_mean\n",
    "            \n",
    "            # 标准化\n",
    "            if sample_data_std != 0:\n",
    "                sample_data /= sample_data_std\n",
    "        \n",
    "            # 更新数据\n",
    "            data[i, j, :] = sample_data\n",
    "    print(\"The shape of EEG is\", data.shape)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# 对源信号进行归一化\n",
    "def custom_prep_source(data):\n",
    "    \n",
    "    # 将数据类型转换为 np.float32\n",
    "    data = data.astype(np.float32)\n",
    "    \n",
    "    for i, y_sample in enumerate(data):\n",
    "        max_abs_vals=np.array(np.max(abs(data[i])))\n",
    "        max_abs_vals[max_abs_vals == 0] = 1\n",
    "        data[i] /= max_abs_vals   \n",
    "\n",
    "    print(\"The shape of source is\", data.shape)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def make_3d(matrix):\n",
    "    # 如果矩阵的维度不是3，则增加一个维度\n",
    "    if matrix.ndim != 3:\n",
    "        # 在前面增加一个维度\n",
    "        nrow, ncol = matrix.shape\n",
    "        matrix_3d = matrix.reshape((1, nrow, ncol))\n",
    "        return matrix_3d\n",
    "    else:\n",
    "        return matrix\n",
    "\n",
    "def wight_combined_loss(y_true, y_pred):\n",
    "    \n",
    "    # # 设定权重\n",
    "    # binary_array=tf.where(y_true != 0, 1, 0)\n",
    "    # binary_array = tf.cast(binary_array, dtype=tf.float32)\n",
    "    # y_true_filtered = tf.multiply(binary_array, y_true)\n",
    "    # y_pred_filtered = tf.multiply(binary_array, y_pred)\n",
    "\n",
    "    # 创建一个掩码，标记非零值\n",
    "    mask = tf.not_equal(y_true, 0)\n",
    "    # 使用掩码过滤出非零元素\n",
    "    y_true_filtered = tf.boolean_mask(y_true, mask)\n",
    "    y_pred_filtered = tf.boolean_mask(y_pred, mask)\n",
    "\n",
    "    # MSE Loss\n",
    "    huber = tf.keras.losses.Huber()(y_true, y_pred)\n",
    "    huber2 = tf.keras.losses.MeanSquaredError()(y_true_filtered, y_pred_filtered)\n",
    "    \n",
    "    # Cosine Similarity Loss\n",
    "    # 使用 tf.keras.losses.cosine_similarity，并确保结果为正值\n",
    "    cosine_loss = 1+tf.keras.losses.CosineSimilarity()(y_true, y_pred)\n",
    "    \n",
    "    # 组合损失，确保使用 tf.cast 保持类型一致\n",
    "    combined = 1* huber + 1*cosine_loss\n",
    "    #combined = 1000 * huber + cosine_loss + huber2\n",
    "    #combined = 1000 * huber + huber2\n",
    "\n",
    "    return combined\n",
    "\n",
    "def non_zero_mse_loss(y_true, y_pred):\n",
    "\n",
    "    # 创建一个掩码，标记非零值\n",
    "    mask = tf.not_equal(y_true, 0)\n",
    "    \n",
    "    # 使用掩码过滤出非零元素\n",
    "    y_true_filtered = tf.boolean_mask(y_true, mask)\n",
    "    y_pred_filtered = tf.boolean_mask(y_pred, mask)\n",
    "    \n",
    "    # 计算非零元素的均方误差\n",
    "    # mse = tf.square(y_true_filtered - y_pred_filtered)\n",
    "    mse = K.mean(K.square(y_true_filtered - y_pred_filtered))\n",
    "    \n",
    "    # 返回均方误差的平均值\n",
    "    return tf.reduce_mean(mse)\n",
    "\n",
    "def sparsity(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred)) / K.max(K.square(y_pred))\n",
    "def combined_loss2(y_true, y_pred):\n",
    "\n",
    "    print(y_pred.shape)\n",
    "    print(y_true.shape)\n",
    "    # MSE Loss\n",
    "    huber = tf.keras.losses.Huber()(y_true, y_pred)\n",
    "\n",
    "    cosine_loss = sparsity(y_true, y_pred)\n",
    "    \n",
    "    # 组合损失，确保使用 tf.cast 保持类型一致\n",
    "    combined = huber + 0.01 * cosine_loss\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "afdac12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取模型中某一层的输出\n",
    "def get_activations(model, inputs, layer_name=None):\n",
    "    inp = model.input\n",
    "    for layer in model.layers:\n",
    "        if layer.name == layer_name:\n",
    "            Y = layer.output\n",
    "    model = tf.keras.Model(inp,Y)\n",
    "    out = model.predict(inputs)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9e39979a-e7af-4345-807c-0bf32aab0ae1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Simplified_Hybrid_Model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input (InputLayer)             [(None, None, 60)]   0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 200)    12200       ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, None, 200)    40200       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, None, 200)    40200       ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, None, 200)    0           ['dense[0][0]',                  \n",
      "                                                                  'dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.tanh (TFOpLambda)      (None, None, 200)    0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, None, 200)    0           ['tf.math.tanh[0][0]']           \n",
      "                                                                                                  \n",
      " BiLSTM1 (Bidirectional)        (None, None, 200)    128800      ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, None, 400)    0           ['dropout[0][0]',                \n",
      "                                                                  'BiLSTM1[0][0]']                \n",
      "                                                                                                  \n",
      " BiLSTM2 (Bidirectional)        (None, None, 400)    961600      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, None, 400)   800         ['BiLSTM2[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, None, 400)   821136      ['layer_normalization[0][0]',    \n",
      " dAttention)                                                      'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, None, 400)    0           ['multi_head_attention[0][0]',   \n",
      "                                                                  'BiLSTM2[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, None, 400)   800         ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, None, 600)   240600      ['layer_normalization_1[0][0]']  \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, None, 600)    0           ['time_distributed[0][0]']       \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDistri  (None, None, 400)   240400      ['dropout_1[0][0]']              \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, None, 400)    0           ['time_distributed_1[0][0]',     \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " Direct_Output (TimeDistributed  (None, None, 1284)  514884      ['add_2[0][0]']                  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 1284)        0           ['Direct_Output[0][0]']          \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 160)          205600      ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1284)         206724      ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1284)      0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " multiply2 (Multiply)           (None, None, 1284)   0           ['Direct_Output[0][0]',          \n",
      "                                                                  'reshape[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,413,944\n",
      "Trainable params: 3,413,944\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "(1000, 60, 26)\n",
      "(1000, 60, 26)\n",
      "The shape of EEG is (1000, 26, 60)\n",
      "(1, 26, 60)\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "loaded_data = np.load('D:/jupyter_note/SWX_source/Simulated_data/x_test1.npy')\n",
    "y_true = np.load('D:/jupyter_note/SWX_source/Simulated_data/y_test1.npy')\n",
    "# 从文件中加载 sim_test 对象\n",
    "with open( 'D:/jupyter_note/SWX_source/Simulated_data/sim1.pkl', 'rb') as file:\n",
    "    sim_test = pickle.load(file)\n",
    "\n",
    "# 加载保存的模型\n",
    "model1 = load_model('D:/jupyter_note/SWX_source/Simulated_data/model_attention', compile=False)\n",
    "# 定义优化器和损失函数\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0003)\n",
    "loss = wight_combined_loss\n",
    "# 重新编译模型\n",
    "model1.compile(loss=loss, optimizer=optimizer)\n",
    "# 打印模型摘要\n",
    "model1.summary()\n",
    "\n",
    "data=loaded_data\n",
    "print(data.shape)\n",
    "    \n",
    "# 对输入数据进行预处理\n",
    "data_processed = make_3d(data)\n",
    "print(data_processed.shape)\n",
    "X_test = custom_prep_data(data_processed)\n",
    "X_test2 = X_test[40:41, :, :]\n",
    "print(X_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7ecb2b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 133 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001DD6DDE2AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "attention =  [[[3.5797853e-15 2.6555130e-01 4.7206824e-13 ... 8.0850667e-05\n",
      "   6.1562573e-06 6.1295395e-08]]]\n",
      "(1, 1, 1284)\n"
     ]
    }
   ],
   "source": [
    "attention_vectors = []\n",
    "attention_vectors = get_activations(model1, X_test2, layer_name='reshape')\n",
    "print('attention = ', attention_vectors)\n",
    "print(attention_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "adfa50bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(26, 1284)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x1db636098e0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys; sys.path.insert(0, '../')\n",
    "from esinet import util\n",
    "from esinet import Net\n",
    "from esinet.forward import create_forward_model, get_info\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# 去掉第一个维度 (1, 1, 1284) -> (1284,)\n",
    "wighted_squeezed = np.squeeze(attention_vectors)\n",
    "\n",
    "# 扩展为 (26, 1284)，重复元素\n",
    "wighted_expanded = np.tile(wighted_squeezed, (26, 1))\n",
    "\n",
    "# 检查结果\n",
    "print(wighted_expanded.shape)  # 应该输出 (26, 1284)\n",
    "\n",
    "plot_params = dict(surface='white', initial_time=0.05, views=('dorsal'), hemi='both', colormap='hot', background='white', add_data_kwargs=dict(fmin=0,fmid=0.5, fmax=1,scale_factor=0.1), verbose=0)\n",
    "y_hat = np.swapaxes(wighted_expanded, 0, 1) # 得到的源信号维度(n_samples,n_channels, n_times)\n",
    "stc = sim_test.source_data[4]\n",
    "stc_hat = stc.copy()\n",
    "# stc_hat.data = comp.decode(y_hat.T)\n",
    "stc_hat.data = y_hat\n",
    "stc_hat.plot(**plot_params)#将神经网络模型的预测结果可视化，通过 stc_hat.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3290ee0b-1444-460d-8281-c2bc982a98b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "运行时间：0.6607427597045898 秒\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No such layer: reshape_11. Existing layers are: ['Input', 'dense', 'dense_1', 'dense_2', 'add', 'tf.math.tanh', 'dropout', 'BiLSTM1', 'concatenate', 'BiLSTM2', 'layer_normalization', 'multi_head_attention', 'add_1', 'layer_normalization_1', 'time_distributed', 'dropout_1', 'time_distributed_1', 'add_2', 'Direct_Output', 'global_average_pooling1d', 'dense_6', 'dense_7', 'reshape', 'multiply2'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \u001b[38;5;66;03m# 记录结束时间\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m运行时间：\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time \u001b[38;5;241m-\u001b[39m start_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 秒\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m attention_weights \u001b[38;5;241m=\u001b[39m \u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape_11\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39moutput\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# 获取该层的权重\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattention_weights\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\deeplearning\\anaconda3\\envs\\Keras\\lib\\site-packages\\keras\\engine\\training.py:2828\u001b[0m, in \u001b[0;36mModel.get_layer\u001b[1;34m(self, name, index)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m name:\n\u001b[0;32m   2827\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m layer\n\u001b[1;32m-> 2828\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo such layer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Existing layers are: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2829\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(layer\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2830\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProvide either a layer name or layer index at \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2831\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`get_layer`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: No such layer: reshape_11. Existing layers are: ['Input', 'dense', 'dense_1', 'dense_2', 'add', 'tf.math.tanh', 'dropout', 'BiLSTM1', 'concatenate', 'BiLSTM2', 'layer_normalization', 'multi_head_attention', 'add_1', 'layer_normalization_1', 'time_distributed', 'dropout_1', 'time_distributed_1', 'add_2', 'Direct_Output', 'global_average_pooling1d', 'dense_6', 'dense_7', 'reshape', 'multiply2']."
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys; sys.path.insert(0, '../')\n",
    "from esinet import util\n",
    "from esinet import Net\n",
    "from esinet.forward import create_forward_model, get_info\n",
    "from scipy.stats import pearsonr\n",
    "import time\n",
    "\n",
    "\n",
    "# 将脑源活动可视化\n",
    "plot_params = dict(surface='white', initial_time=0.05, views=('lateral'), hemi='both', colorbar=None, background='white', verbose=0)\n",
    "start_time = time.time()\n",
    "y_pred = model1.predict(X_test)[0] # 用于对测试数据进行预测，得到预测值y_hat\n",
    "end_time = time.time()  # 记录结束时间\n",
    "print(f\"运行时间：{end_time - start_time} 秒\")\n",
    "\n",
    "attention_weights = model1.get_layer('reshape_11').output\n",
    "\n",
    "# 获取该层的权重\n",
    "print(f\"weights: {attention_weights.shape}\")\n",
    "\n",
    "y_pred1 = np.swapaxes(y_pred, 0, 1) # 得到的源信号维度(n_samples,n_channels, n_times)\n",
    "y_hat = y_pred1 # 提取其中一个实例进行可视化，x_test1_10源用3 6，3源用4,11  2源用16 20  1源用40\n",
    "print(y_hat.shape)\n",
    "\n",
    "y_true = custom_prep_source(y_true)\n",
    "\n",
    "stc = sim_test.source_data[4]\n",
    "\n",
    "#stc.data = y_true[1]\n",
    "stc.plot(**plot_params)#通过stc.plot将模拟的真实脑源活动可视化\n",
    "print(stc.data.shape)\n",
    "stc_hat = stc.copy()\n",
    "# stc_hat.data = comp.decode(y_hat.T)\n",
    "stc_hat.data = y_hat\n",
    "stc_hat.plot(**plot_params)#将神经网络模型的预测结果可视化，通过 stc_hat.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3a6341-4ebd-4270-aa90-d449601dacab",
   "metadata": {},
   "outputs": [],
   "source": [
    "stc.data = y_true[40] # 1源用45画图\n",
    "plt.figure()\n",
    "plt.axes([0.1, 0.275, 0.85, 0.625])\n",
    "hl = plt.plot(stc.times, stc.data.mean(0), \"b\", label=\"True\")[0]\n",
    "hr = plt.plot(stc.times, stc_hat.data.mean(0), \"g\", label=\"Est\")[0]\n",
    "#plt.xlabel(\"Time (s)\")\n",
    "#plt.ylabel(\"Source amplitude\")\n",
    "plt.xlim(stc.times[0], stc.times[-1])\n",
    "plt.tick_params(axis='x', labelsize=15)  # 设置x轴刻度标签的大小为14\n",
    "plt.tick_params(axis='y', labelsize=15)  # 设置y轴刻度标签的大小为14\n",
    "plt.legend(fontsize=14)  # 显示图例\n",
    "#plt.savefig('GRU.tif', dpi=300)  # 保存为 PNG 格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf27dcc-a02e-43a1-a7c3-58b3768f33c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印基本信息\n",
    "print(\"STC 类型:\", type(stc))\n",
    "print(\"STC 数据维度:\", stc.data.shape)  # 数据的形状，例如 (顶点数, 时间点数)\n",
    "print(\"STC 时间点数:\", len(stc.times))  # 时间点的数量\n",
    "print(\"STC 采样率:\", stc.sfreq)         # 采样频率\n",
    "\n",
    "# 假设 stc_hat 是一个包含脑源活动数据的 SourceEstimate 对象\n",
    "# 计算每个顶点的平均激活强度\n",
    "average_activations = np.mean(stc_hat.data, axis=1)\n",
    "# 获取顶点索引和对应的平均激活强度\n",
    "vertex_activation_pairs = list(enumerate(average_activations))\n",
    "# 根据激活强度对顶点进行排序\n",
    "vertex_activation_pairs.sort(key=lambda x: x[1], reverse=True)  # 按照激活强度从高到低排序\n",
    "# 输出前几个最活跃的脑区\n",
    "for vertex, activation in vertex_activation_pairs[:10]:  # 这里以前10个最活跃的脑区为例\n",
    "    print(f\"Vertex {vertex} has an average activation of {activation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e3405e-a659-4c5e-a3c7-14a6303abec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印最强源的坐标\n",
    "pos = np.load('pos.npy')\n",
    "# 打印加载后的数组\n",
    "print(pos.shape)\n",
    "source_positions = pos\n",
    "# 打印所有的输出，而不是只显示前几个\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "num_sources = len(source_positions)\n",
    "print(\"Number of Source Positions:\", num_sources)\n",
    "# 获取排序后的索引\n",
    "sorted_indices = np.argsort(average_activations)[::-1]\n",
    "# 根据排序后的索引输出激活强度\n",
    "# sorted_activation = average_activations[sorted_indices]\n",
    "# print(\"Sorted activation based on average activation:\")\n",
    "# print(sorted_activation)\n",
    "# print(\"\\nSorted indices based on average activation:\")\n",
    "# print(sorted_indices)\n",
    "# 输出对应的源坐标\n",
    "print(\"\\nCorresponding source positions:\")\n",
    "for idx in sorted_indices[:10]: # 这里以前10个最活跃的脑区为例\n",
    "    print(source_positions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bef560-fa44-46bc-9a76-05b3827bd268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对结果进行评价\n",
    "from esinet.evaluate import auc_metric\n",
    "y_true = np.swapaxes(y_true, 1,2)\n",
    "# 调用 auc_metric 函数，计算平均AUC，注意这里的y_true 维度: (1000, 25, 1284)，y_pred 维度: (1000, 25, 1284)\n",
    "#mean_auc = auc_metric(y_true, y_pred)\n",
    "# 输出平均 AUC\n",
    "#print(\"平均 AUC across samples:\", mean_auc)\n",
    "#del mean_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae78d3-e866-4c00-9f65-4c8d9fcd16d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算多个样本的 NMSE\n",
    "from esinet.evaluate import eval_nmse\n",
    "\n",
    "nmse_values = []\n",
    "\n",
    "for y_true_, y_pred_ in zip(y_true, y_pred):\n",
    "    \n",
    "    # 计算每个样本的 NMSE\n",
    "    nmse_sample = eval_nmse(y_true_, y_pred_)\n",
    "    nmse_values.append(nmse_sample)\n",
    "\n",
    "# 计算平均 MSE 和 NMSE\n",
    "mean_nmse = np.mean(nmse_values)\n",
    "\n",
    "# 计算标准差\n",
    "nmse_std = np.std(nmse_values)\n",
    "\n",
    "# 输出结果\n",
    "np.savetxt('NMSE.csv', nmse_values, fmt='%.5f')\n",
    "print(\"平均 NMSE across samples:\", mean_nmse)\n",
    "print(\"NMSE 的标准差:\", nmse_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca51dab1-4b75-4729-9d13-6117cbae6e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 计算多个样本的 MLE\n",
    "from esinet.evaluate import eval_mean_localization_error\n",
    "\n",
    "def evals(y_true, y_hat, pos):\n",
    "    n_samples, n_time = y_true.shape[:2]\n",
    "    n_samples = int(n_samples/5)   # 节省时间\n",
    "    mles = np.zeros((n_samples,))\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        sample_mles = np.zeros((n_time,))\n",
    "\n",
    "        for j in range(n_time):\n",
    "            sample_mles[j] = eval_mean_localization_error(y_true[i, j], y_hat[i, j], pos)\n",
    "\n",
    "        # 在计算平均值之前检查 sample_mles 是否为空\n",
    "        if not np.isnan(sample_mles).all():\n",
    "            mles[i] = np.nanmean(sample_mles)\n",
    "\n",
    "    # 对样本取平均值\n",
    "    avg_mle = np.nanmean(mles)\n",
    "\n",
    "    # 计算标准差\n",
    "    mle_std = np.nanstd(mles)\n",
    "\n",
    "    return mles, avg_mle, mle_std\n",
    "\n",
    "# 调用 evals 函数并打印结果\n",
    "mles, avg_mle_result, mle_std_result = evals(y_true, y_pred, pos)\n",
    "np.savetxt('MLE.csv', mles, fmt='%.5f')\n",
    "print(\"模型1—平均 MLE across samples:\", avg_mle_result)\n",
    "print(\"MLE 的标准差:\", mle_std_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece3b1b0-e285-4b90-8c27-81c4b4c5569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算多个样本的 AUC\n",
    "from esinet.evaluate import auc_metric\n",
    "# 调用 auc_metric 函数，计算平均AUC，注意这里的y_true 维度: (1000, 25, 1284)，y_pred 维度: (1000, 25, 1284)\n",
    "auc_values = []\n",
    "\n",
    "for y_true_, y_pred_ in zip(y_true, y_pred):\n",
    "    \n",
    "    # 计算每个样本的 NMSE\n",
    "    auc_sample,auc_std = auc_metric(y_true_, y_pred_)\n",
    "    auc_values.append(auc_sample)\n",
    "\n",
    "# 计算平均 MSE 和 NMSE\n",
    "mean_auc = np.mean(auc_values)\n",
    "\n",
    "# 计算标准差\n",
    "std_auc = np.std(auc_values)\n",
    "\n",
    "# 输出平均 AUC\n",
    "np.savetxt('AUC.csv', auc_values, fmt='%.5f')\n",
    "print(\"平均 AUC across samples:\", mean_auc)\n",
    "print(\"AUC 的标准差:\", std_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5a2431-2031-4b39-901e-b922319861ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "##计算每一个样本的相关性和p值，找到相关性最强的样本，并将这个样本的预测脑图和真实脑图进行绘制\n",
    "from scipy.stats import pearsonr\n",
    "from tqdm.notebook import tqdm\n",
    "# 模型预测和评估：\n",
    "best_sample_idx_model = None\n",
    "best_r_model = -1  # 初始值设为一个较小的值，确保它会被更新\n",
    "best_p_value_model = 1  # 初始值设为一个较大的值，确保它会被更新\n",
    "average_r_model = 0  # 初始化累计变量\n",
    "correlations=[]\n",
    "n_samples, n_time = y_true.shape[:2]\n",
    "\n",
    "for idx in tqdm(range(n_samples)):\n",
    "    n = sim_test.simulation_info[\"number_of_sources\"].values[idx]\n",
    "    #print(f\"{n} source(s)\")\n",
    "\n",
    "    # 模型1的预测和评估\n",
    "    r_model, p_value_model = pearsonr(y_pred[idx].flatten(), y_true[idx].flatten())\n",
    "    correlations.append(np.abs(r_model))\n",
    "\n",
    "    # 更新最佳样本信息\n",
    "    if r_model > best_r_model:\n",
    "        best_r_model = r_model\n",
    "        best_p_value_model = p_value_model\n",
    "        best_sample_idx_model = idx\n",
    "         # 累计结果\n",
    "    average_r_model += r_model\n",
    "\n",
    "# 计算平均值\n",
    "np.savetxt('CC.csv', correlations, fmt='%.5f')\n",
    "average_r_model /= n_samples\n",
    "variance_r_model = np.std(correlations)\n",
    "print(f\"model1: Average r={average_r_model:.2f}\")\n",
    "print(f\"model1: Average r={variance_r_model:.2f}\")\n",
    "# 输出每个模型的最佳样本信息\n",
    "# print(f\"Best Sample Index - {model1.name}: {best_sample_idx_model}\")\n",
    "# print(f\"{model1.name}: r={best_r_model:.2f}, p-value={best_p_value_model:.4f}\")\n",
    "# 使用每个模型的最佳样本的结果进行脑图可视化\n",
    "#stc = sim_test.source_data[best_sample_idx_model1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25085031-dadd-4768-b5bd-beaaec800733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算AUC_close指标\n",
    "# from esinet.evaluate import eval_auc\n",
    "# def calculate_avg_auc_close_with_std(y_true, y_hat, pos):\n",
    "#     n_samples = y_true.shape[0]\n",
    "#     n_time = y_true.shape[1]\n",
    "#     n_samples = int(n_samples/2)   # 节省时间\n",
    "#     aucs_close = np.zeros((n_samples, n_time))\n",
    "\n",
    "#     for i in range(n_samples):\n",
    "#         sample_aucs_close = np.zeros((n_time,))\n",
    "\n",
    "#         for j in range(n_time):\n",
    "#             auc_close, _ = eval_auc(y_true[i, j], y_hat[i, j], pos)\n",
    "#             sample_aucs_close[j] = auc_close\n",
    "\n",
    "#         # Take the mean across time for each sample\n",
    "#         aucs_close[i] = sample_aucs_close\n",
    "\n",
    "#     # Take the mean across samples\n",
    "#     avg_auc_close = np.mean(aucs_close)\n",
    "#     auc_close_std = np.std(aucs_close)\n",
    "\n",
    "#     return avg_auc_close, auc_close_std\n",
    "\n",
    "# 使用新的函数计算 avg_auc_close 和标准差\n",
    "# avg_auc_close_result, auc_close_std_result = calculate_avg_auc_close_with_std(y_true, y_pred, pos)\n",
    "# # 输出结果\n",
    "# print(\"模型1—平均 AUC_close across samples:\", avg_auc_close_result)\n",
    "# print(\"AUC_close 的标准差:\", auc_close_std_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307fa59f-d801-495f-bc82-837bb1b220c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算AUC_far指标\n",
    "# def calculate_avg_auc_far_with_std(y_true, y_hat, pos):\n",
    "#     n_samples = y_true.shape[0]\n",
    "#     n_time = y_true.shape[1]\n",
    "#     n_samples = int(n_samples/2)   # 节省时间\n",
    "#     aucs_far = np.zeros((n_samples, n_time))\n",
    "\n",
    "#     for i in range(n_samples):\n",
    "#         sample_aucs_far = np.zeros((n_time,))\n",
    "\n",
    "#         for j in range(n_time):\n",
    "#             _, auc_far = eval_auc(y_true[i, j], y_hat[i, j], pos)\n",
    "#             sample_aucs_far[j] = auc_far\n",
    "\n",
    "#         # Take the mean across time for each sample\n",
    "#         aucs_far[i] = sample_aucs_far\n",
    "\n",
    "#     # Take the mean across samples\n",
    "#     avg_auc_far = np.mean(aucs_far)\n",
    "#     auc_far_std = np.std(aucs_far)\n",
    "\n",
    "#     return avg_auc_far, auc_far_std\n",
    "\n",
    "# 使用新的函数计算 avg_auc_far 和标准差\n",
    "# avg_auc_far_result, auc_far_std_result = calculate_avg_auc_far_with_std(y_true, y_pred, pos)\n",
    "\n",
    "# # 输出结果\n",
    "# print(\"模型1—平均 AUC_far across samples:\", avg_auc_far_result)\n",
    "# print(\"AUC_far 的标准差:\", auc_far_std_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1320a8d2-03ca-47de-94d4-4ca4553d824b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
