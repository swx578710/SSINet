{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4947dd72-8315-4eb2-b379-df0acb186242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy import io\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "import sys;\n",
    "from esinet.evaluate import eval_mse\n",
    "# sys.path.insert(0, '../')\n",
    "from esinet import Simulation, Net, util, evaluate\n",
    "from forward import create_forward_model, get_info\n",
    "from matplotlib import pyplot as plt\n",
    "from esinet.util import calculate_source\n",
    "import pickle\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cbf8373-e0bc-4b95-bfd8-ef028b36f53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_prep_data(data):\n",
    "\n",
    "    data = np.swapaxes(data, 1,2)\n",
    "\n",
    "    # 获取数据维度\n",
    "    num_samples, num_timepoints, num_channels = data.shape\n",
    "    \n",
    "    # 将数据类型转换为 np.float32\n",
    "    data = data.astype(np.float32)\n",
    "    \n",
    "    # 对每个样本（脑电信号的一个时间点）进行处理\n",
    "    for i in range(num_samples):\n",
    "        for j in range(num_timepoints):\n",
    "            # 获取当前样本的数据\n",
    "            sample_data = data[i, j, :]\n",
    "            \n",
    "            # 假设你想要进行去除平均值和标准化的预处理\n",
    "            # 去除平均值\n",
    "            sample_data_mean = np.mean(sample_data)\n",
    "            sample_data_std = np.std(sample_data)\n",
    "            sample_data -= sample_data_mean\n",
    "            \n",
    "            # 标准化\n",
    "            if sample_data_std != 0:\n",
    "                sample_data /= sample_data_std\n",
    "        \n",
    "            # 更新数据\n",
    "            data[i, j, :] = sample_data\n",
    "    print(\"The shape of EEG is\", data.shape)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# 对源信号进行归一化\n",
    "def custom_prep_source(data):\n",
    "    \n",
    "    # 将数据类型转换为 np.float32\n",
    "    data = data.astype(np.float32)\n",
    "    \n",
    "    for i, y_sample in enumerate(data):\n",
    "        max_abs_vals=np.array(np.max(abs(data[i])))\n",
    "        max_abs_vals[max_abs_vals == 0] = 1\n",
    "        data[i] /= max_abs_vals   \n",
    "\n",
    "    print(\"The shape of source is\", data.shape)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def make_3d(matrix):\n",
    "    # 如果矩阵的维度不是3，则增加一个维度\n",
    "    if matrix.ndim != 3:\n",
    "        # 在前面增加一个维度\n",
    "        nrow, ncol = matrix.shape\n",
    "        matrix_3d = matrix.reshape((1, nrow, ncol))\n",
    "        return matrix_3d\n",
    "    else:\n",
    "        return matrix\n",
    "\n",
    "def wight_combined_loss(y_true, y_pred):\n",
    "    \n",
    "    # # 设定权重\n",
    "    # binary_array=tf.where(y_true != 0, 1, 0)\n",
    "    # binary_array = tf.cast(binary_array, dtype=tf.float32)\n",
    "    # y_true_filtered = tf.multiply(binary_array, y_true)\n",
    "    # y_pred_filtered = tf.multiply(binary_array, y_pred)\n",
    "\n",
    "    # 创建一个掩码，标记非零值\n",
    "    mask = tf.not_equal(y_true, 0)\n",
    "    # 使用掩码过滤出非零元素\n",
    "    y_true_filtered = tf.boolean_mask(y_true, mask)\n",
    "    y_pred_filtered = tf.boolean_mask(y_pred, mask)\n",
    "\n",
    "    # MSE Loss\n",
    "    huber = tf.keras.losses.Huber()(y_true, y_pred)\n",
    "    huber2 = tf.keras.losses.MeanSquaredError()(y_true_filtered, y_pred_filtered)\n",
    "    \n",
    "    # Cosine Similarity Loss\n",
    "    # 使用 tf.keras.losses.cosine_similarity，并确保结果为正值\n",
    "    cosine_loss = 1+tf.keras.losses.CosineSimilarity()(y_true, y_pred)\n",
    "    \n",
    "    # 组合损失，确保使用 tf.cast 保持类型一致\n",
    "    combined = 1* huber + 1*cosine_loss\n",
    "    #combined = 1000 * huber + cosine_loss + huber2\n",
    "    #combined = 1000 * huber + huber2\n",
    "\n",
    "    return combined\n",
    "\n",
    "def non_zero_mse_loss(y_true, y_pred):\n",
    "\n",
    "    # 创建一个掩码，标记非零值\n",
    "    mask = tf.not_equal(y_true, 0)\n",
    "    \n",
    "    # 使用掩码过滤出非零元素\n",
    "    y_true_filtered = tf.boolean_mask(y_true, mask)\n",
    "    y_pred_filtered = tf.boolean_mask(y_pred, mask)\n",
    "    \n",
    "    # 计算非零元素的均方误差\n",
    "    # mse = tf.square(y_true_filtered - y_pred_filtered)\n",
    "    mse = K.mean(K.square(y_true_filtered - y_pred_filtered))\n",
    "    \n",
    "    # 返回均方误差的平均值\n",
    "    return tf.reduce_mean(mse)\n",
    "\n",
    "def sparsity(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred)) / K.max(K.square(y_pred))\n",
    "def combined_loss2(y_true, y_pred):\n",
    "\n",
    "    print(y_pred.shape)\n",
    "    print(y_true.shape)\n",
    "    # MSE Loss\n",
    "    huber = tf.keras.losses.Huber()(y_true, y_pred)\n",
    "\n",
    "    cosine_loss = sparsity(y_true, y_pred)\n",
    "    \n",
    "    # 组合损失，确保使用 tf.cast 保持类型一致\n",
    "    combined = huber + 0.01 * cosine_loss\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afdac12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取模型中某一层的输出\n",
    "def get_activations(model, inputs, layer_name=None):\n",
    "    inp = model.input\n",
    "    for layer in model.layers:\n",
    "        if layer.name == layer_name:\n",
    "            Y = layer.output\n",
    "    model = tf.keras.Model(inp,Y)\n",
    "    out = model.predict(inputs)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e39979a-e7af-4345-807c-0bf32aab0ae1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Simplified_Hybrid_Model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input (InputLayer)             [(None, None, 60)]   0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 200)    12200       ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, None, 200)    40200       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, None, 200)    40200       ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, None, 200)    0           ['dense[0][0]',                  \n",
      "                                                                  'dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.tanh (TFOpLambda)      (None, None, 200)    0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, None, 200)    0           ['tf.math.tanh[0][0]']           \n",
      "                                                                                                  \n",
      " BiLSTM1 (Bidirectional)        (None, None, 200)    128800      ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, None, 400)    0           ['dropout[0][0]',                \n",
      "                                                                  'BiLSTM1[0][0]']                \n",
      "                                                                                                  \n",
      " BiLSTM2 (Bidirectional)        (None, None, 400)    961600      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, None, 400)   800         ['BiLSTM2[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, None, 400)   821136      ['layer_normalization[0][0]',    \n",
      " dAttention)                                                      'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, None, 400)    0           ['multi_head_attention[0][0]',   \n",
      "                                                                  'BiLSTM2[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, None, 400)   800         ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, None, 600)   240600      ['layer_normalization_1[0][0]']  \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, None, 600)    0           ['time_distributed[0][0]']       \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDistri  (None, None, 400)   240400      ['dropout_1[0][0]']              \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, None, 400)    0           ['time_distributed_1[0][0]',     \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " Direct_Output (TimeDistributed  (None, None, 1284)  514884      ['add_2[0][0]']                  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 1284)        0           ['Direct_Output[0][0]']          \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 160)          205600      ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1284)         206724      ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1284)      0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " multiply2 (Multiply)           (None, None, 1284)   0           ['Direct_Output[0][0]',          \n",
      "                                                                  'reshape[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,413,944\n",
      "Trainable params: 3,413,944\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "(1000, 60, 26)\n",
      "(1000, 60, 26)\n",
      "The shape of EEG is (1000, 26, 60)\n",
      "(1, 26, 60)\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "loaded_data = np.load('D:/jupyter_note/SWX_source/Simulated_data/x_test1.npy')\n",
    "y_true = np.load('D:/jupyter_note/SWX_source/Simulated_data/y_test1.npy')\n",
    "# 从文件中加载 sim_test 对象\n",
    "with open( 'D:/jupyter_note/SWX_source/Simulated_data/sim1.pkl', 'rb') as file:\n",
    "    sim_test = pickle.load(file)\n",
    "\n",
    "# 加载保存的模型\n",
    "model1 = load_model('D:/jupyter_note/SWX_source/Simulated_data/model_attention', compile=False)\n",
    "# 定义优化器和损失函数\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0003)\n",
    "loss = wight_combined_loss\n",
    "# 重新编译模型\n",
    "model1.compile(loss=loss, optimizer=optimizer)\n",
    "# 打印模型摘要\n",
    "model1.summary()\n",
    "\n",
    "data=loaded_data\n",
    "print(data.shape)\n",
    "    \n",
    "# 对输入数据进行预处理\n",
    "data_processed = make_3d(data)\n",
    "print(data_processed.shape)\n",
    "X_test = custom_prep_data(data_processed)\n",
    "X_test2 = X_test[40:41, :, :]\n",
    "print(X_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ecb2b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention =  [[[3.5797853e-15 2.6555130e-01 4.7206824e-13 ... 8.0850667e-05\n",
      "   6.1562573e-06 6.1295395e-08]]]\n",
      "(1, 1, 1284)\n"
     ]
    }
   ],
   "source": [
    "attention_vectors = []\n",
    "attention_vectors = get_activations(model1, X_test2, layer_name='reshape')\n",
    "print('attention = ', attention_vectors)\n",
    "print(attention_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adfa50bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 1284)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x218b1ba9d30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys; sys.path.insert(0, '../')\n",
    "from esinet import util\n",
    "from esinet import Net\n",
    "from esinet.forward import create_forward_model, get_info\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# 去掉第一个维度 (1, 1, 1284) -> (1284,)\n",
    "wighted_squeezed = np.squeeze(attention_vectors)\n",
    "\n",
    "# 扩展为 (26, 1284)，重复元素\n",
    "wighted_expanded = np.tile(wighted_squeezed, (26, 1))\n",
    "\n",
    "# 检查结果\n",
    "print(wighted_expanded.shape)  # 应该输出 (26, 1284)\n",
    "\n",
    "plot_params = dict(surface='white', initial_time=0.05, views=('dorsal'), hemi='both', colormap='hot', background='white', add_data_kwargs=dict(fmin=0,fmid=0.5, fmax=1,scale_factor=0.1), verbose=0)\n",
    "y_hat = np.swapaxes(wighted_expanded, 0, 1) # 得到的源信号维度(n_samples,n_channels, n_times)\n",
    "stc = sim_test.source_data[4]\n",
    "stc_hat = stc.copy()\n",
    "# stc_hat.data = comp.decode(y_hat.T)\n",
    "stc_hat.data = y_hat\n",
    "stc_hat.plot(**plot_params)#将神经网络模型的预测结果可视化，通过 stc_hat.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1320a8d2-03ca-47de-94d4-4ca4553d824b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
