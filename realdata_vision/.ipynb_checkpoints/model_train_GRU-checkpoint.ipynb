{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "3367e635-b5d7-42d1-8c0d-170f23c6c36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, TimeDistributed, Bidirectional, LSTM, multiply, Input, Dropout, Conv1D, Flatten, GRU, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import LayerNormalization, MultiHeadAttention, Add, concatenate, GaussianNoise, Layer, BatchNormalization, Reshape\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.activations import relu, elu, tanh\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from esinet import util\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from esinet import Simulation, Net\n",
    "from esinet.forward import create_forward_model, get_info\n",
    "import numpy as np\n",
    "import copy\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "85344297-e008-410e-a19e-4e0f3a8aa4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "    x = Add()([x, inputs])\n",
    "\n",
    "    # Feed Forward Part\n",
    "    ff = LayerNormalization(epsilon=1e-6)(x)\n",
    "    ff = TimeDistributed(Dense(ff_dim, activation=\"relu\"))(ff)\n",
    "    ff = Dropout(dropout)(ff)\n",
    "    ff = TimeDistributed(Dense(inputs.shape[-1]))(ff)\n",
    "    ff = Add()([ff, x])\n",
    "\n",
    "    return ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "6989ead3-4c51-4985-a20d-728518f6455d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_attention_module(input_tensor, reduction_ratio=8):\n",
    "    # 获取输入通道数\n",
    "    channels = input_tensor.shape[-1]\n",
    "    \n",
    "    # 压缩阶段\n",
    "    squeeze = GlobalAveragePooling1D()(input_tensor)\n",
    "    \n",
    "    # 激励阶段\n",
    "    excitation = Dense(channels // reduction_ratio, activation='relu')(squeeze)\n",
    "    excitation = Dense(channels, activation='sigmoid')(excitation)\n",
    "    \n",
    "    # 将激励层的输出调整形状以匹配原始输入的形状\n",
    "    excitation = Reshape((1, channels))(excitation)\n",
    "    \n",
    "    # 重标定阶段，逐元素乘法\n",
    "    scale = multiply([input_tensor, excitation],  name=\"multiply2\")\n",
    "    \n",
    "    return scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b23856cb-f2fc-4148-9c1c-e8dc38ababf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "def myself_loss(y_true, y_pred):\n",
    "\tlosses = y_true - y_pred\n",
    "\treturn losses\n",
    "\n",
    "def wight_combined_loss(y_true, y_pred):\n",
    "    \n",
    "    # # 设定权重\n",
    "    # binary_array=tf.where(y_true != 0, 1, 0)\n",
    "    # binary_array = tf.cast(binary_array, dtype=tf.float32)\n",
    "    # y_true_filtered = tf.multiply(binary_array, y_true)\n",
    "    # y_pred_filtered = tf.multiply(binary_array, y_pred)\n",
    "\n",
    "    # 创建一个掩码，标记非零值\n",
    "    mask = tf.not_equal(y_true, 0)\n",
    "    # 使用掩码过滤出非零元素\n",
    "    y_true_filtered = tf.boolean_mask(y_true, mask)\n",
    "    y_pred_filtered = tf.boolean_mask(y_pred, mask)\n",
    "\n",
    "    # MSE Loss\n",
    "    huber = tf.keras.losses.Huber()(y_true, y_pred)\n",
    "    huber2 = tf.keras.losses.MeanSquaredError()(y_true_filtered, y_pred_filtered)\n",
    "    \n",
    "    # Cosine Similarity Loss\n",
    "    # 使用 tf.keras.losses.cosine_similarity，并确保结果为正值\n",
    "    cosine_loss = 1+tf.keras.losses.CosineSimilarity()(y_true, y_pred)\n",
    "    \n",
    "    # 组合损失，确保使用 tf.cast 保持类型一致\n",
    "    combined = 1000 * huber + 1*cosine_loss\n",
    "    #combined = 1000 * huber + 1*cosine_loss + huber2\n",
    "\n",
    "    return combined\n",
    "\n",
    "def wight_combined_loss2(y_true, y_pred):\n",
    "    \n",
    "    # 设定权重\n",
    "    weights = tf.where(tf.not_equal(y_true, 0), 1.0, 0.01)\n",
    "    # 计算加权MSE\n",
    "    wmse=tf.reduce_mean(weights * tf.square(y_true - y_pred))\n",
    "\n",
    "    # MSE Loss\n",
    "    huber = tf.keras.losses.Huber(delta=0.5)(y_true, y_pred)\n",
    "    # huber2 = tf.keras.losses.Huber(delta=0.1)(y_true_filter, y_pred_filter)\n",
    "    \n",
    "    # Cosine Similarity Loss\n",
    "    # 使用 tf.keras.losses.cosine_similarity，并确保结果为正值\n",
    "    cosine_loss = 1+tf.keras.losses.CosineSimilarity()(y_true, y_pred)\n",
    "    \n",
    "    # 组合损失，确保使用 tf.cast 保持类型一致\n",
    "    # combined = 1000 * huber + 1*cosine_loss + 100 * huber2\n",
    "    combined = 1000 * huber + 1*cosine_loss + 1000*wmse\n",
    "\n",
    "    return combined\n",
    "\n",
    "def data_loss2(leadfield, lam_0=0.1):\n",
    "    leadfield_ = tf.cast(leadfield, dtype=tf.float32)\n",
    "    def batch_data_loss(y_true, y_est):\n",
    "        def d_loss(y_true, y_est):\n",
    "            y_true_eeg = tf.transpose(tf.matmul(leadfield_, tf.transpose(y_true)))\n",
    "            y_est_eeg = tf.transpose(tf.matmul(leadfield_, tf.transpose(y_est)))\n",
    "            # print(\"y_true \", y_true)\n",
    "            # print(\"y_est \", y_est)\n",
    "            error_source = tf.keras.losses.CosineSimilarity(name=\"Source_Data_Cosine_Loss\")(y_est, y_true)\n",
    "            error_eeg = tf.keras.losses.CosineSimilarity(name=\"EEG_Data_Cosine_Loss\")(y_est_eeg, y_true_eeg)\n",
    "            return error_source*lam_0 + error_eeg\n",
    "\n",
    "        batched_losses = tf.map_fn(lambda x:\n",
    "            d_loss(x[0], x[1]), \n",
    "            (y_true, y_est), dtype=tf.float32)\n",
    "        return K.mean(batched_losses)\n",
    "\n",
    "\n",
    "    return batch_data_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "fde9ac92-78d9-45d0-a7f7-e69d14451a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对输入eeg进行归一化\n",
    "def custom_prep_data(data):\n",
    "\n",
    "    data = np.swapaxes(data, 1,2)\n",
    "\n",
    "    # 获取数据维度\n",
    "    num_samples, num_timepoints, num_channels = data.shape\n",
    "    \n",
    "    # 将数据类型转换为 np.float32\n",
    "    data = data.astype(np.float32)\n",
    "    \n",
    "    # 对每个样本（脑电信号的一个时间点）进行处理\n",
    "    for i in range(num_samples):\n",
    "        for j in range(num_timepoints):\n",
    "            # 获取当前样本的数据\n",
    "            sample_data = data[i, j, :]\n",
    "            \n",
    "            # 假设你想要进行去除平均值和标准化的预处理\n",
    "            # 去除平均值\n",
    "            sample_data_mean = np.mean(sample_data)\n",
    "            sample_data_std = np.std(sample_data)\n",
    "            sample_data -= sample_data_mean\n",
    "            \n",
    "            # 标准化\n",
    "            if sample_data_std != 0:\n",
    "                sample_data /= sample_data_std\n",
    "        \n",
    "            # 更新数据\n",
    "            data[i, j, :] = sample_data\n",
    "    print(\"The shape of EEG is\", data.shape)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# 对源信号进行归一化\n",
    "def custom_prep_source(data):\n",
    "    \n",
    "    # 将数据类型转换为 np.float32\n",
    "    data = data.astype(np.float32)\n",
    "    \n",
    "    for i, y_sample in enumerate(data):\n",
    "        max_abs_vals=np.array(np.max(abs(data[i])))\n",
    "        max_abs_vals[max_abs_vals == 0] = 1\n",
    "        data[i] /= max_abs_vals   \n",
    "\n",
    "    data = np.swapaxes(data, 1,2)\n",
    "    print(\"The shape of source is\", data.shape)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "f287b6a0-fe37-433e-986c-815976091200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义学习率调度函数\n",
    "def lr_schedule(epoch):\n",
    "    # 根据训练周期(epoch)来动态调整学习率\n",
    "    if epoch < 50:\n",
    "        return 0.0003  # 0.0005\n",
    "    elif epoch < 100:\n",
    "        return 0.0003  # 0.0003\n",
    "    elif epoch < 150:\n",
    "        return 0.0001  # 0.0002\n",
    "    else:\n",
    "        return 0.00005  # 0.0001\n",
    "\n",
    "# 创建学习率调度器,损失函数有余弦相似度 CosineSimilarity, tf.keras.losses.Huber(), MeanAbsoluteError, MeanSquaredError\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "7dea1584-d54a-43a4-93e1-343f9644802e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Simplified_Hybrid_Model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input (InputLayer)             [(None, None, 32)]   0           []                               \n",
      "                                                                                                  \n",
      " dense_110 (Dense)              (None, None, 200)    6600        ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_111 (Dense)              (None, None, 200)    40200       ['dense_110[0][0]']              \n",
      "                                                                                                  \n",
      " dense_112 (Dense)              (None, None, 200)    40200       ['dense_111[0][0]']              \n",
      "                                                                                                  \n",
      " add_42 (Add)                   (None, None, 200)    0           ['dense_110[0][0]',              \n",
      "                                                                  'dense_112[0][0]']              \n",
      "                                                                                                  \n",
      " tf.math.tanh_14 (TFOpLambda)   (None, None, 200)    0           ['add_42[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_28 (Dropout)           (None, None, 200)    0           ['tf.math.tanh_14[0][0]']        \n",
      "                                                                                                  \n",
      " BiLSTM1 (Bidirectional)        (None, None, 200)    106400      ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenate)   (None, None, 400)    0           ['dropout_28[0][0]',             \n",
      "                                                                  'BiLSTM1[0][0]']                \n",
      "                                                                                                  \n",
      " BiLSTM2 (Bidirectional)        (None, None, 500)    1302000     ['concatenate_14[0][0]']         \n",
      "                                                                                                  \n",
      " layer_normalization_28 (LayerN  (None, None, 500)   1000        ['BiLSTM2[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_14 (Multi  (None, None, 500)   1026036     ['layer_normalization_28[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " add_43 (Add)                   (None, None, 500)    0           ['multi_head_attention_14[0][0]',\n",
      "                                                                  'BiLSTM2[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_29 (LayerN  (None, None, 500)   1000        ['add_43[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " time_distributed_28 (TimeDistr  (None, None, 512)   256512      ['layer_normalization_29[0][0]'] \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " dropout_29 (Dropout)           (None, None, 512)    0           ['time_distributed_28[0][0]']    \n",
      "                                                                                                  \n",
      " time_distributed_29 (TimeDistr  (None, None, 500)   256500      ['dropout_29[0][0]']             \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " add_44 (Add)                   (None, None, 500)    0           ['time_distributed_29[0][0]',    \n",
      "                                                                  'add_43[0][0]']                 \n",
      "                                                                                                  \n",
      " Direct_Output (TimeDistributed  (None, None, 1284)  643284      ['add_44[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_14 (G  (None, 1284)        0           ['Direct_Output[0][0]']          \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_116 (Dense)              (None, 160)          205600      ['global_average_pooling1d_14[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_117 (Dense)              (None, 1284)         206724      ['dense_116[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_14 (Reshape)           (None, 1, 1284)      0           ['dense_117[0][0]']              \n",
      "                                                                                                  \n",
      " multiply2 (Multiply)           (None, None, 1284)   0           ['Direct_Output[0][0]',          \n",
      "                                                                  'reshape_14[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,092,056\n",
      "Trainable params: 4,092,056\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 超参数定义\n",
    "n_channels = 32\n",
    "n_dipoles = 1284\n",
    "n_dense_units = 200  # 减少单元数\n",
    "n_lstm_units = 32    # 减少单元数\n",
    "dropout_rate = 0.2\n",
    "batch_size = 256\n",
    "epochs = 200\n",
    "noise_factor=0.1\n",
    "lam_0=0.1\n",
    "\n",
    "# 输入层\n",
    "inputs = tf.keras.Input(shape=(None, n_channels), name='Input')\n",
    "noisy_input = GaussianNoise(stddev=noise_factor)(inputs, training=True) # 添加噪声层\n",
    "## 全连接路径\n",
    "fc1 = TimeDistributed(Dense(n_dense_units, \n",
    "            activation=\"tanh\"), \n",
    "            name='FC1')(inputs)\n",
    "fc1 = Dropout(dropout_rate)(fc1)\n",
    "direct_out = TimeDistributed(Dense(n_dipoles, \n",
    "    activation=\"linear\"),\n",
    "    name='FC2')(fc1)\n",
    "# LSTM路径,Mask层的作用是生成一个与输入序列形状相同的掩码，用于动态地控制对输出序列的处理，以处理变长时间序列\n",
    "# 在源定位中，不同信号的长度可能不同，但我们通常希望在模型中对它们进行统一处理。这就需要通过掩码来标记填充的部分，并在计算损失时忽略这些填充的部分。\n",
    "lstm1 = Bidirectional(GRU(n_lstm_units, return_sequences=True, \n",
    "    input_shape=(None, n_dense_units), dropout=dropout_rate), \n",
    "    name='LSTM1')(fc1)\n",
    "mask = TimeDistributed(Dense(n_dipoles, \n",
    "            activation=\"sigmoid\"), \n",
    "            name='Mask')(lstm1)\n",
    "\n",
    "# Combination\n",
    "multi = multiply([direct_out, mask], name=\"multiply\")\n",
    "model = tf.keras.Model(inputs=inputs, outputs=multi, name='Contextualizer')\n",
    "model.compile(loss=data_loss2(leadfield, lam_0=lam_0), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "\n",
    "# 打印模型概要\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "0f45b428-7827-45be-b1c8-2658493a6128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 32, 26)\n",
      "(20000, 1284, 26)\n"
     ]
    }
   ],
   "source": [
    "# 加载测试数据\n",
    "x= np.load('D:/jupyter_note/SWX_source/vision_realdata/x10.npy')\n",
    "y= np.load('D:/jupyter_note/SWX_source/vision_realdata/y10.npy')\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c1cb47b7-8abf-4c92-9934-87a5125b3e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of EEG is (20000, 26, 32)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.49 GiB for an array with shape (20000, 1284, 26) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[231], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 对信号进行预处理\u001b[39;00m\n\u001b[0;32m      2\u001b[0m x \u001b[38;5;241m=\u001b[39m custom_prep_data(x)\n\u001b[1;32m----> 3\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mcustom_prep_source\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[227], line 38\u001b[0m, in \u001b[0;36mcustom_prep_source\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcustom_prep_source\u001b[39m(data):\n\u001b[0;32m     36\u001b[0m     \n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# 将数据类型转换为 np.float32\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, y_sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data):\n\u001b[0;32m     41\u001b[0m         max_abs_vals\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(np\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;28mabs\u001b[39m(data[i])))\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.49 GiB for an array with shape (20000, 1284, 26) and data type float32"
     ]
    }
   ],
   "source": [
    " # 对信号进行预处理\n",
    "x = custom_prep_data(x)\n",
    "y = custom_prep_source(y)\n",
    "# y = np.swapaxes(y, 1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10311a34-042b-4c73-91d7-c7b88295f38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用数据生成器进行训练\n",
    "def data_generator(x, y, batch_size):\n",
    "    num_samples = len(x)\n",
    "    indices = np.arange(num_samples)\n",
    "    \n",
    "    while True:\n",
    "        np.random.shuffle(indices)\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            batch_indices = indices[i:i + batch_size]\n",
    "            yield x[batch_indices], y[batch_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9dc45c-bb55-4420-a472-15c125689bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "split_index = int(0.9 * len(x))\n",
    "x_train, x_val = x[:split_index], x[split_index:]\n",
    "y_train, y_val = y[:split_index], y[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361c1691-4363-4f67-94e6-b98e1abd9a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators for training and validation\n",
    "train_generator = data_generator(x_train, y_train, batch_size)\n",
    "val_generator = data_generator(x_val, y_val, batch_size)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=20, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a36e7c-5b6b-4b09-ba24-d01f529a64b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算每个epoch的步骤和验证步骤\n",
    "steps_per_epoch = len(x_train) // batch_size\n",
    "validation_steps = len(x_val) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa333345-1fbc-4855-b857-b93b95f5649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型时使用学习率调度器\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[early_stopping, lr_scheduler]  # 添加学习率调度器回调\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9d7c34-9013-4fe1-902b-cb13924bca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制验证损失和训练损失\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] = [u'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 设置字体大小\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# 设置图像大小\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# 绘制训练和验证损失\n",
    "plt.plot(history.history['loss'], label='训练损失')\n",
    "plt.plot(history.history['val_loss'], label='验证损失')\n",
    "plt.xlabel('迭代次数')\n",
    "plt.ylabel('损失')\n",
    "plt.title('原始模型 训练和验证损失')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928d1676-dd80-43c3-9ae9-dea85884889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "model.save('D:/jupyter_note/SWX_source/vision_realdata/model_GRU', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a17f64-b959-476f-8487-678742157ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
